{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1451513,"sourceType":"datasetVersion","datasetId":798386}],"dockerImageVersionId":29985,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"As per date (Aug 26, 2020):\n* Coronavirus Cases: 24,005,460\n* Deaths: 821,578\n* Recovered: 16,485,396\n\nStay Home, Stay Safe.\n\nWe will deep dive into the dataset and find interesting insights. Created visualisations using plotly library and did dataset manipulation using numpy package.\n\nTo Do:\n* Importing Libraries\n* EDA and Visualisations\n* Sentiment Analysis\n* Results\n\nHope you like it! <font color = \"red\">Please Upvote!</font>\n\n![](https://pbs.twimg.com/media/EQgP2pUW4AA0BkC?format=jpg&name=medium)","metadata":{}},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime as dt\nimport missingno as msno\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom wordcloud import WordCloud, STOPWORDS\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize, sent_tokenize #(word tokenize, sentence tokenize)\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom bs4 import BeautifulSoup\nimport re, string, unicodedata\n\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\nfrom wordcloud import ImageColorGenerator\nfrom textblob import TextBlob\n\nimport plotly.offline\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport cufflinks as cf\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable = True)\n%matplotlib inline","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"tweets = pd.read_csv('../input/covid19-tweets/covid19_tweets.csv')\ntweets.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tweets.info()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tweets.describe()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Missing Values Visualisation**","metadata":{}},{"cell_type":"code","source":"msno.matrix(tweets)\n#white lines tells the missing values.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Adding Additional Columns**","metadata":{}},{"cell_type":"code","source":"tweets['date'] = pd.to_datetime(tweets[\"date\"])\ntweets['count'] = 1\ntweets['tweet_date'] = tweets['date'].apply(lambda x: x.date())\ntweets['day_sent'] = tweets['date'].dt.strftime('%a')\ntweets['month_sent'] = tweets['date'].dt.strftime('%b')\ntweets['hour_sent'] = tweets['date'].apply(lambda x: x.hour)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tweets.head(3)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"**Tweet Counts Vs Verified User Tweets**","metadata":{}},{"cell_type":"code","source":"groupedby_date = tweets.groupby('tweet_date').sum().reset_index()\n\nfig = go.Figure(data=[\n    go.Bar(name = 'Verified Users', x = groupedby_date['tweet_date'], y = groupedby_date['user_verified'].tolist()),\n    go.Bar(name = 'Count Of Tweets', x = groupedby_date['tweet_date'], y= groupedby_date['count'].tolist())])\n\nfig.update_layout(barmode='stack')\nfig.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Coorelation Matrix**","metadata":{}},{"cell_type":"code","source":"#Correlation matrix\ntweets[['user_followers', 'user_friends',\n        'user_favourites', 'user_verified']].corr().iplot(kind='heatmap',\n                                                          colorscale=\"Blues\",\n                                                          title=\"Feature Correlation Matrix\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Word Cloud (Hashtags)**","metadata":{}},{"cell_type":"code","source":"hashtags = tweets['hashtags'].dropna().tolist()\nunique_hashtags=(\" \").join(hashtags)\n\nresponse = requests.get('https://www.lifewire.com/thmb/Q-QChfPXsb8id3pvLrcXsn2oQNs=/768x0/filters:no_upscale():max_bytes(150000):strip_icc()/twitterlogo-6471b86764ac4076b70f645e632b899e.jpg')\nchar_mask = np.array(Image.open(BytesIO(response.content)))\nimage_colors = ImageColorGenerator(char_mask)\nplt.figure(figsize = (15,15))\nwc = WordCloud(background_color=\"black\", max_words=200, width=400, height=400, mask=char_mask, random_state=1).generate(unique_hashtags)\n# to recolour the image\nplt.imshow(wc.recolor(color_func=image_colors))","metadata":{"trusted":true,"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Top 15 Regions : Tweet Counts**","metadata":{}},{"cell_type":"code","source":"#Top15_regions\nTop15_regions = pd.DataFrame(tweets['user_location'].value_counts().sort_values(ascending=False)[:15]).T\ncolors = ['lightslategray',] * 15\ncolors[0] = 'crimson'\n\nfig = go.Figure(data=[go.Bar(x=Top15_regions.columns,\n                             y=[Top15_regions[i][0] for i in Top15_regions],\n                             marker_color=colors)])\nfig.update_layout(title_text='Tweets on User Location')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Top 10 Sources : To Do Tweets**","metadata":{}},{"cell_type":"code","source":"Top10_source = pd.DataFrame(tweets['source'].value_counts().sort_values(ascending=False)[:10]).T\ncolors = ['lightslategray',] * 10\ncolors[0] = 'crimson'\n\nfig = go.Figure(data=[go.Bar(x=Top10_source.columns,\n                             y=[Top10_source[i][0] for i in Top10_source],\n                             marker_color=colors)])\nfig.update_layout(title_text='Different source used for tweeting.')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Heatmap: Tweet Counts as per month and days**","metadata":{}},{"cell_type":"code","source":"days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\nmonths = ['Jul', 'Aug']\n\ngrouped_by_month_and_day = tweets.groupby(['month_sent', 'day_sent']).sum().reset_index()[['month_sent', 'day_sent', 'count']]\npt = grouped_by_month_and_day.pivot_table(index = 'month_sent', columns = 'day_sent', values = 'count').reindex(index = months, columns = days)\npt.iplot(kind='heatmap',colorscale=\"Blues\", title=\"Heatmap of tweets count as per month and days\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Timeline: Tweet Counts on 24hrs basis**","metadata":{}},{"cell_type":"code","source":"grouped_by_time = tweets.groupby('hour_sent').sum().reset_index().sort_values(by = 'count', ascending = False)\nfig = px.bar(grouped_by_time, x='hour_sent', y='count', color='hour_sent', \n             labels={'pop':'Count Of Tweets'}, height=400)\nfig.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Most Used Words: Tweet**","metadata":{}},{"cell_type":"code","source":"#Most Used Words in tweets\nword_dict = dict.fromkeys(tweets['user_name'].unique()) #collecting all unique userids\nfor key in word_dict.keys():\n  word_dict[key] = {}\n\nfor name, msg in zip(tweets['user_name'], tweets['text']):\n  for word in msg.split():\n    #any media is included then that is excluded\n    if word not in ['<Media', 'omitted>']:\n      if word in word_dict[name]:\n        word_dict[name][word] += 1\n      else:\n        word_dict[name][word] = 1\n\nfor name in tweets['user_name'].unique():\n  word_dict[name] = {k: v for k, v in sorted(word_dict[name].items(), \n                                             key = lambda item: item[1], reverse= True)}","metadata":{"trusted":true,"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"grouped_df = tweets.groupby('user_name').sum().reset_index()\ngrouped_df['Most used words'] = grouped_df['user_name'].apply(lambda x : word_dict[x])\ngrouped_df[['user_name', 'Most used words']]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Tweet Analysis ","metadata":{}},{"cell_type":"markdown","source":"# Vocabulary","metadata":{}},{"cell_type":"code","source":"#crating vocab for the tweets\ndef get_corpus(text):\n    words = []\n    for i in text:\n        for j in i.split():\n            words.append(j.strip())\n    return words\n\ncorpus = get_corpus(tweets.text)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import Counter\ncounter = Counter(corpus)\nmost_common_words = counter.most_common(10) #prining most common 10 words\nmost_common_words = dict(most_common_words)\nmost_common_words","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Cleaning","metadata":{}},{"cell_type":"code","source":"#Data Cleaning - Part-1\nstop_words = set(stopwords.words('english')) #set of all stopwords\npunctuation = list(string.punctuation) #all punctuation\n#adding everything into one set\nstop_words.update(punctuation)\n\ndef strip_html(text):\n    soup = BeautifulSoup(text, 'html.parser')\n    return soup.get_text()\n\ndef square_brackets(text):\n    return re.sub('\\[[^]]*\\]', '', text)\n\ndef url_extract(text):\n    return re.sub(r'http\\S+', '', text)\n\ndef stopwords(text):\n    final_text = []\n    for i in text.split():\n        #checking in stopwords and also lowering the text\n        if i.strip().lower() not in stop_words:\n            final_text.append(i.strip())\n    return \" \".join(final_text)\n\n#finally getting all outputs in preprocessing the text using above functions\ndef preprocess(text):\n    text = strip_html(text)\n    text = square_brackets(text)\n    text = url_extract(text)\n    text = stopwords(text)\n    return text","metadata":{"trusted":true,"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tweets['text'] = tweets['text'].apply(preprocess)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#processed tweets\ntweets['text'].head(5)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# WordCloud: Tweets","metadata":{}},{"cell_type":"code","source":"response = requests.get('https://miro.medium.com/proxy/1*SZq4F67FpMACqyQ1-doAFA.jpeg')\nchar_mask = np.array(Image.open(BytesIO(response.content)))\nimage_colors = ImageColorGenerator(char_mask)\n\nplt.figure(figsize = (20,20))\nwc = WordCloud(background_color=\"black\", max_words=200, width=400, height=400, mask=char_mask, random_state=1).generate(\" \".join(tweets.text))\n# to recolour the image\nplt.imshow(wc.recolor(color_func=image_colors), interpolation=\"bilinear\")","metadata":{"trusted":true,"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Sentiment Analysis","metadata":{}},{"cell_type":"code","source":"sid = SentimentIntensityAnalyzer()\n\ntweets['sentiment_vader'] = tweets['text'].apply(lambda x: sid.polarity_scores(x)['compound'])\ntweets['sentiment_textblob'] = tweets['text'].apply(lambda x: TextBlob(x).sentiment.polarity)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Negative Tweets: Top 15**","metadata":{}},{"cell_type":"code","source":"tweets.sort_values(by = 'sentiment_textblob')[['user_name', 'text',\n                                               'sentiment_vader', 'sentiment_textblob']].head(15)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Positive Tweets: Top 15**","metadata":{}},{"cell_type":"code","source":"#Positive Tweets\ntweets.sort_values(by = 'sentiment_textblob', ascending = False)[['user_name', 'text', 'sentiment_vader', 'sentiment_textblob']].head(15)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Neutral Tweets: Top15**","metadata":{}},{"cell_type":"code","source":"#Neutral Tweets\ntweets[tweets['sentiment_textblob'] == 0.0][['user_name', 'text', 'sentiment_vader', 'sentiment_textblob']].head(15)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"code","source":"#Combining all Dataframes (Positive, Neutral and Negative) and visualising the results...\nneutral = tweets[tweets['sentiment_textblob'] == 0.0]\npositive = tweets[tweets['sentiment_textblob'] > 0.0]\nnegative = tweets[tweets['sentiment_textblob'] < 0.0]\n\nneutral['Sentiment Category'] = 'Neutral'\npositive['Sentiment Category'] = 'Positive'\nnegative['Sentiment Category'] = 'Negative'\n\nframes = [neutral, positive, negative]\nresult = pd.concat(frames)","metadata":{"trusted":true,"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"colors = ['gold', 'mediumturquoise', 'darkorange']\nfig = px.pie(result, values='count', names='Sentiment Category',\n             color_discrete_sequence=px.colors.sequential.RdBu,\n             title = 'Tweets Distribution Based on Sentiments')\nfig.update_traces(textposition='inside', textinfo='percent+label', textfont_size=20,\n                  marker=dict(colors=colors, line=dict(color='#000000', width=2)))\nfig.show()","metadata":{"trusted":true,"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# The End","metadata":{}}]}